# A
- name: "algorithm"
  wiki: "Algorithm"
  definition: "is a set of rules in problem-solving operations. Creating algorithms is a foundation of programming, where a developer defines a finite sequence of well-defined instructions to perform computations and process data. Among the typical elements of an algorithm, regardless of programming language, are conditionals and loops that enable repetitive actions and logical decisions."
- name: "artificial-intelligence"
  wiki: "Artificial_intelligence"
  definition: "is a branch of Computer Science dealing with cognitive technology and simulation of intelligent behavior, including planning, learning, reasoning, problem-solving, knowledge representation, perception, motion, and manipulation. AI systems can range from simple rule-based systems to complex machine learning models that improve over time by learning from data."
# B
- name: "bash"
  wiki: "Bash_(Unix_shell)"
  definition: "is a command language in the Unix shell that allows users to execute various processes by writing text commands in the terminal window. While the Unix shell is a general interface for command execution, BASH (Bourne Again SHell) is a specific implementation that offers enhanced features like scripting capabilities, improved command-line editing and customizable user environments."
- name: "bash-scripting"
  wiki: "Shell_script"
  definition: "is the process of writing scripts using the BASH language to automate tasks in the Unix shell. It allows users to combine multiple commands into a single script file and execute repetitive tasks efficiently. Bash scripting allows users to simplify or automate operations performed on text or multiple files, including numerical calculations, saving time and reducing the potential for errors by eliminating the need to do it manually in the GUI or enter each command every time you need it."
- name: "big-data"
  wiki: "Big_data"
  definition: "focuses on the large size of data, its variety, and the velocity of generating and processing. These parameters continually expand and become a bottleneck on existing computational approaches. It also integrates modern (i) analytical techniques (e.g., machine learning), (ii) technologies (e.g., distributed computing), and (iii) visualization solutions (e.g., interactive graphing and infographics), applied during the life cycle of Big Data."
- name: "binary"
  wiki: "Binary_code"
  definition: "is a numbering system where data is expressed in the base-2. It is a mathematical expression which uses only two symbols, typically 0 and 1 to represent data."
# C
- name: "cluster"
  wiki: "Computer_cluster"
  definition: "or a computer cluster is a group of computing machines or servers that work together as a single system. Clusters provide high performance computing and parallel processing by distribution of tasks across multiple machines."
- name: "code"
  wiki: "Source_code"
  definition: "in programming is a set of instructions for the computer. Code is written using programming language(s) and can be used to run a process, task, software, system, etc. on a computer."
- name: "command-line"
  wiki: "Command-line_interface"
  definition: "is a text interface for the computer that passes the predefined commands to the operating system. Commands trigger the execution of various processes. These commands trigger the execution of various processes, allowing users to perform tasks such as file manipulation, program execution and system management directly through text input in the terminal window."
- name: "computing-tools"
  wiki: "Computing"
  definition: "*(in this workbook)* refer to the resources and technologies that support computer-powered computations in research. This includes High-Performance Computing (HPC), cloud computing, specialized computer software, high-speed networking, and programming tools. These tools facilitate efficient and effective data processing, analysis and computation, enabling researchers to handle complex and large-scale tasks with enhanced speed and precision."
- name: "container"
  wiki: "Containerization_(computing)"
  definition: "is a executable package of specific application code and its dependencies. A software container includes all necessary elements needed to run the software such that it can be run in any environment/system."
# D
- name: "data-manipulation"
  wiki: "Data_processing"
  definition: "is the process of adjusting, organizing, and transforming data to make it suitable for analysis. In the context of data processing, data preparation, or data wrangling, especially in research, it involves tasks like cleaning data, merging datasets, and converting data formats to ensure accuracy and consistency for subsequent analysis. It should not be confused with <a href='https://en.wikipedia.org/wiki/Misuse_of_statistics#Data_manipulation' target='_blank'>intentional data manipulation</a> in statistical analyses, which is a serious issue that undermines the transparency and honesty of research."
- name: "data-preview"
  wiki: ""
  definition: "is the process of viewing data without downloading it, particularly useful for data stored remotely on HPC systems. This can be achieved through various methods such as using command-line tools like `less`, `more` and `head` to quickly view text files, mounting folders with `sshfs` to access remote files as if they were local and utilizing X11-forwarding for running graphical applications remotely with local display. Additionally, Open OnDemand (OOD) provides a web-based interface for browsing and previewing files, while tools like Jupyter notebooks facilitate remote data visualization directly in the browser. These approaches enhance efficiency by allowing users to inspect data quickly and conveniently without transferring large files."
- name: "data-science"
  wiki: "Data_science"
  definition: "is a modern conception of efficient computational processing of large sets of digital information for data mining and knowledge discovery. Data Science focuses on solving various technical challenges related to Big Data and developing innovative techniques unique to digital data (e.g., Machine Learning). It is a highly interdisciplinary field using the latest developments in Computer & Information Science, also strongly supported by Mathematics and Statistics, and complemented by specific Domain Knowledge."
- name: "data-transfer"
  wiki: "Data_communication"
  definition: "is the process of moving data from one location to another, which can be between different devices, systems or network locations. In the context of HPC and research, data transfer involves using secure and efficient methods to handle large datasets. Tools such as SCP (Secure Copy Protocol), SFTP (Secure File Transfer Protocol) and Globus facilitate data transfer, ensuring integrity and speed while minimizing the risk of data loss or corruption. Efficient data transfer is crucial for collaborative research, backup and data analysis."
- name: "data-types"
  wiki: ""
  definition: "refer to the various forms in which data can exist and be utilized across different contexts. In classical data types, we have structured data (organized in predefined formats like databases and spreadsheets) and unstructured data (lacking specific structure, such as text documents and images). In programming, data types include primitive types (integers, floats, booleans), composite types (arrays, lists, tuples), objects, data frames (e.g., pandas DataFrame in Python), arrays (e.g., NumPy arrays) and matrices. Additionally, data types encompass various file formats like text files (TXT, CSV), binary files (EXE, BIN), markup languages (XML, HTML) and specialized formats (HDF5, JSON) for specific data storage and exchange needs."
- name: "data-wrangling"
  wiki: "Data_wrangling"
  definition: "is the process of transforming raw data into a usable format according to your project’s requirements."
- name: "digital-data"
  wiki: "Digital_data"
  definition: "is a collection of observables registered in a computer-readable representation. A single item of data is called a datum. Each datum has assigned the binary value of “false, 0” or “true, 1”, resulting in a bit of information, i.e., one binary digit."
- name: "distributed-computing"
  wiki: "Distributed_computing"
  definition: "is a system of multiple computer machines connected over a network to create a computing cluster that appears as a single computer to the end-user. It provides a unified environment with access to shared resources (software, data, storage) and coordinated computing power. Distributed computing is a technique typically used in the High-Performance Computing (HPC) infrastructures."
# E
- name: "environment"
  wiki: "Deployment_environment#Development"
  definition: "is a workspace for developers where they create and modify the source code of their application (software, web, etc.). Nowadays, professional developers usually use an Integrated Development Environment (IDE) that is a software suite partially with a graphical interface to make various things easier for the programmer (general code management, tracking and pushing changes, file system browsing, file preview & editing, kernel loading, autocomplete, formatting, etc.); programming environment, is a layer of settings specific for a given programming language or type of developed application. It can be isolated from the general operating system and provides a kind of virtual environment with adjusted software configuration or modules loaded in a selected release. Virtual environments are commonly used when programming in Python and can be easily created using Conda ( environment management system)."
# F
- name: "file-system"
  wiki: "File_system"
  definition: "is the organization of data retained in the digital storage on the computing machine. The content consists of hierarchically ordered folders and files. Folders are user-categorized containers for files. Files contain data and consume digital storage space. Some files belong to the operating system and include configurations, source code, and executables of various programs. Each file and folder is assigned an absolute path that defines its location in the file system. Knowing this path is very useful for navigating the file system from the command line."
# G
- name: "gnuplot"
  wiki: "Gnuplot"
  definition: "is a free program that can generate two- and three-dimensional plots of functions, data, and data fits. It works as both command-line and GUI interface. You can export graphic files in a variety of formats (SVG, PNG, etc.) or analyze the results interactively, customizing the graph as you wish."
- name: "GUI"
  wiki: "Graphical_user_interface"
  definition: "short for Graphical User Interface, is an interface through which users interact with computers and other electronic devices using icons and other visual elements."
# H
- name: "hpc"
  wiki: "High-performance_computing"
  definition: "is the practice of performing computations that require more power than a single computer can provide. HPC utilizes dedicated infrastructure within the framework of distributed computing, combining the power of multiple computers through networks such as computer clusters, supercomputers and cloud-based services. This aggregation allows for the efficient processing of complex tasks that demand significant computational resources."
- name: "HTML"
  wiki: "HTML"
  definition: "HyperText Markup Language is the standard language for webpages. HTML is used to display the contents of a website on a web browser."
# I
- name: "IDE"
  wiki: "Integrated_development_environment"
  definition: "is an application for software development that includes a code editor, debugging tools, and version control system. IDE softwares are designed to make the process of writing, testing, and debugging code easier and more efficient."
- name: "information"
  wiki: "Information"
  definition: "is a meaningful and organized product of data processing. It maintains data compression, encapsulates densification of value and veracity, and provides context for querying in the analysis."
- name: "interactive-graphing"
  wiki: "Category:Plotting_software"
  definition: "is a method for data visualization that enables users to interact with the data on-the-fly, see the details such as numerical values, and freely customize the final plot. That is a modern approach that gives greater insight into the dataset and allows for collaborative work on data analysis."
# J
- name: "job-scheduling"
  wiki: "Batch_processing"
  definition: "is the process of managing and allocating computational tasks across shared computing resources such as HPC infrastructure. Since multiple users need to access these resources, job scheduling ensures an equal or prioritized distribution by gathering jobs into a queue for batch processing. These jobs are then sent to different nodes for computation, optimizing memory allocation and computer power usage. Job scheduling systems like SLURM and PBS automate this process, balancing the computational demand with the available processing power to maximize the efficiency and throughput of the HPC infrastructure, minimizing waiting times and ensuring fair access for all users."
- name: "jupyter"
  wiki: "Project_Jupyter"
  definition: "is an integrated development environment (IDE) with an interactive web-based computing interface that supports programming in multiple languages, including Python, Java, R, Julia, Matlab, Octave, etc. The Jupyter interface has a form of a notebook, where you can do it all at once, (i) develop and execute code cells, (ii) write comments and documentation in markdown, and (iii) visualize and analyze results with an interactive graphing."
# K
- name: "kernel"
  wiki: "IPython#Project_Jupyter"
  definition: "in computing is the core of the operating system. It is the system that connects the hardware with the software. Kernel is responsible for management of memory, tasks, and processes."
- name: "knowledge"
  wiki: "Knowledge"
  definition: "is an extracted non-trivial insight from the data classification and analysis of information. Knowledge, while applied, leads to problem-solving, improvements, and steady development."
# L
- name: "library"
  wiki: "Library_(computing)"
  definition: "in programming is a collection of prewritten code designed to be used for common tasks. Programming libraries provide reusable functions, classes, and routines that developers can integrate into their own programs. For example, Numpy in Python is used for working with large arrays of data, offering a wide range of mathematical and statistical functions. Libraries help developers save time and effort by leveraging existing solutions, ensuring consistency, and improving code reliability."
- name: "library-package-module"
  wiki: "Modular_programming"
  definition: "is a collection of pre-written source code, dependencies, and modules available for use in programming. In the context of HPC clusters, these modules are pre-installed and can be easily loaded to provide essential functions and tools, streamlining development and ensuring compatibility with various software requirements. They help developers save time by reusing code and avoiding the need to build software from scratch."
- name: "linux"
  wiki: "Linux"
  definition: "is a family of operating systems that includes Ubuntu, Debian, Fedora, etc. These are open-source operating systems based on the Linux kernel."
- name: "local-machine"
  wiki: ""
  definition: "is the computer that the user is using with direct access to it. Usually, it is your personal computer."
- name: "loop"
  wiki: "Control_flow#Loops"
  definition: "is a set of code that is written in such a way that it performs a task repetitively until a condition is met."
# M
- name: "machine-learning"
  wiki: "Machine_learning"
  definition: "is a field of study focused on developing advanced computer algorithms that search for deeply coupled patterns in massive, disparate data and enable knowledge extraction. Machine learning methods are trained with large sets of data, and they learn from examples to make intelligent decisions without being explicitly programmed."
- name: "module"
  wiki: "Modular_programming"
  definition: "is a small piece of a larger program. Modular programming is a way to design software such that each module is independent and can be used to execute a part of the function."
# N
- name: "nextflow"
  wiki: "Nextflow"
  definition: "is a domain specific language used for bioinformatics data analysis. It uses software containers and enables reproducible scientific workflows."
- name: "node"
  wiki: "Computer_cluster"
  definition: "is a unit in an HPC cluster. It can be a single computer or a server in a collection that makes the cluster."
# O
- name: "OOD"
  wiki: "Open OnDemand"
  definition: "is a web-based interface that provides easy and flexible access to High-Performance Computing (HPC) resources. It allows users to manage computational tasks, transfer files and access software applications from any location using a web browser. OOD simplifies the process of interacting with HPC systems by offering an intuitive interface, eliminating the need for complex command-line operations, and enabling users to monitor and control their jobs, visualize data and collaborate more effectively."
- name: "operating-system"
  wiki: "Operating_system"
  definition: "OS, is the core software on the computer that manages computing resources, performes installations, and executes available programs. Command-line interface (CLI) and Graphical User Interface (GUI) enable the user directly interact with the operating system to set up, configure, and troubleshoot it. Among the popular operating systems are Windows, Mac OS, and Linux."
# P
- name: "plotting"
  wiki: "Plot_(graphics)"
  definition: "is the process of creating visual representations of data to facilitate understanding and analysis. In the context of research and data science, plotting involves using tools and libraries, such as `Matplotlib`, `Plotly` and `ggplot2`, to generate graphs, charts and plots. These visualizations help in identifying patterns, trends and outliers in the data, making it easier to interpret results and communicate findings effectively."
- name: "programming"
  wiki: "Programming_language"
  definition: "means creating a set of instructions for a computer on how to execute operations in order, following the assumptions and logical conditions of the algorithm. Many programming languages facilitate communication between the code developer and the computing machine. Bash enables a shell scripting using a command-line interpreter for automating repetitive tasks by executing pre-defined commands according to requested conditionals and loops. More advanced analytical operations, including mathematical and statistical functions, modifying complex data structures, or processing non-text data, usually require a higher-level programming language such as Python or C++."
- name: "pseudocode"
  wiki: "Pseudocode"
  definition: "is a representation of code or algorithm, summarizing the code. It is a readable step by step description of what the program should do."
# Q
- name: "queue"
  wiki: "Job_queue"
  definition: "in distributed computing, it is an organized list (sequence) of tasks submitted to the job scheduler that manages the computational resources and decides to start or stop the task. The queue is ordered by wait time, user priority, and availability of requested resources. When the combination of these factors is advantageous, the submitted task begins executing, and so its status changes from waiting to running. The queuing system is typical for distributed computing, such as a network of computer clusters shared by more users. Some of the most popular workload managers are SLURM and PBS."
# R
- name: "raw-data"
  wiki: "Raw_data"
  definition: "is the data captured from the source and has not been processed before the use. It usually has a large volume and serves as a primary unfiltered input in Data Science."
- name: "remote-access"
  wiki: "Remote_access"
  definition: "is the ability to connect to and use a computer or network from a different location through the internet or another network. This allows users to access files, applications, and system resources as if they were physically present at the remote location. Tools like SSH (Secure Shell) and VPN (Virtual Private Network) facilitate secure remote access, enabling efficient and flexible work, troubleshooting and system management from anywhere. Open OnDemand (OOD) provides a web-based interface for accessing HPC resources, making it easier for users to manage their computational tasks remotely."
- name: "remote-machine"
  wiki: ""
  definition: "is any other computer or computing network that the user can access by logging into the external network. Performing actions on a remote machine requires a secure login and often requires the user to have an account created by the network administrator. In scientific projects, we use remote computing machines as part of the HPC infrastructure to access high-performance computing and collaboratively share big data."
# S
- name: "SLURM"
  wiki: "Slurm_Workload_Manager"
  definition: "Simple Linux Utility for Resource Management is a cluster management and job scheduling system. It is used in management of the HPC cluster environments."
- name: "structured-data"
  wiki: "Data_model"
  definition: "is highly organized in terms of easy digital deciphering. That includes a standardized format, enduring order, and categorization in a well-determined arrangement that facilitates managing and querying datasets in various combinations. A typical example of an organized data structure is a spreadsheet or relational database."
- name: "system-setup"
  wiki: "Operating_system"
  definition: "refers to the process of installing and/or configuring an operating system (OS) on a personal (local) machine, as well as setting up a user account on an HPC cluster (remote machine), including HOME directory management. This involves steps to ensure the command-line interface (CLI) is functional and the installation of useful tools such as office suites, development environments, and graphic software to enhance productivity and reproducibility. Proper system setup maximizes the efficiency and capabilities of the computing tool, allowing users to effectively utilize both local machines and remote HPC resources."
# T
- name: "terminal"
  wiki: "Terminal_emulator"
  definition: "is a program for accessing files on your computer using the command line."
- name: "text-manipulation"
  wiki: "Text_Utilities"
  definition: "is the process of modifying and organizing text to achieve a desired format or structure. In the context of GNU Core Utilities, it involves using command-line tools like `cat`, `cut`, `tr` or `sort` to perform operations such as reading, replacing, extracting and sorting text data. These tools enable efficient and automated handling of text files, simplifying complex text processing tasks."
# U
- name: "unix-shell"
  wiki: "Unix_shell"
  definition: "is a command-line interpreter that provides a command-line user interface for a computer’s operating system (OS). The OS uses shell scripts/commands to control the execution of the programs and procedures."
- name: "unstructured-data"
  wiki: "Unstructured_data"
  definition: "has no organized structure that can be easily detected, processed, and categorized by computer algorithms. This type of data is usually massive and descriptive in nature. A good example is the streams of highly varied text (e.g., emails, social media posts, online blogs, newspapers, books, and scientific publications), audio and video recording, images and photos, data from various sensors (weather, traffic), and medical records."
# V
- name: "virtual-environment"
  wiki: "Virtual_environment"
  definition: "is an isolated workspace created to manage and run specific projects without affecting the system's global settings. It allows developers to install and use different versions of software packages and dependencies tailored to a project. Example <a href='https://en.wikipedia.org/wiki/Virtual_environment_software' target='_blank'>virtual environment software</a> includes `virtualenv`, `venv` and `conda` for managing environments and Python packages. These tools help ensure project consistency and prevent conflicts between dependencies in different projects."
- name: "visualization"
  wiki: "Data_and_information_visualization"
  definition: "is a highly visually influential and semantically meaningful form of modern communication methods. In Data Science, interactive graphing and creating concise infographics support both the ease of extracting insights and the opportunity for deeper analysis for those interested. That contributes to better knowledge retention."
# W
- name: "web-browser"
  wiki: "Web_browser"
  definition: "is an application used to access internet and browse websites and web pages."
- name: "workdir"
  wiki: "Working_directory"
  definition: "is a working directory for a project or computational task. It often appears as a variable or instruction that can be assigned a path to a selected location in the file system. That path is then used for all future commands that require a location, such as writing to a file. It is a common variable for workload managers on distributed computing infrastructures. The pathname of the current working directory can be accessed with the ‘pwd’ command or using the ‘$PWD’ environmental variable."
